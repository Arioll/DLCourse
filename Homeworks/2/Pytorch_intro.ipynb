{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q2I2EQUXWm1n"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"5eHK_r-mHj3E","colab_type":"text"},"source":["Почему Pytorch?\n","1. Pytorch просто использовать\n","2. Мощная поддержка GPU\n","3. Много имплементированных алгоритмов\n","4. Хорошо подходит для академических исследований с данными \n","5. Автоматическое дифференцирование вычислительного графа\n","6. Похож на Numpy\n","\n","Другие фреймворки: Pytorch, Tensorflow, Caffe, Chainer, MXNet, Keras\n"]},{"cell_type":"markdown","metadata":{"id":"92X8_yBmIRbt","colab_type":"text"},"source":["1. Матричное умножение\n","\n","В Pytorch есть экивалент Numpy array - это torch tensor "]},{"cell_type":"code","metadata":{"id":"deOGSGG2Iksh","colab_type":"code","outputId":"4524c102-7fb4-428f-ad97-472416b75fd2","executionInfo":{"status":"ok","timestamp":1570551086015,"user_tz":-180,"elapsed":652,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import torch\n","\n","torch.tensor([[2,3,5],[1,2,9]])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2, 3, 5],\n","        [1, 2, 9]])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"sTIkHI-4InkY","colab_type":"code","outputId":"9da1fd5d-0feb-4777-c0bd-a8e28ad24482","executionInfo":{"status":"ok","timestamp":1570551095345,"user_tz":-180,"elapsed":700,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import numpy as np\n","\n","np.array([[2,3,5],[1,2,9]])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2, 3, 5],\n","       [1, 2, 9]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"LfV7GLpJI-ho","colab_type":"code","outputId":"0fe27a57-78f3-4a1c-dfac-94aa546d3818","executionInfo":{"status":"ok","timestamp":1570551099531,"user_tz":-180,"elapsed":766,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["torch.rand((2,2)) # random matrix"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8459, 0.7135],\n","        [0.9312, 0.1722]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"PgDubrRsJACO","colab_type":"code","colab":{}},"source":["a_t = torch.zeros(2,2)\n","b_t = torch.ones(2,2)\n","c_t = torch.eye(2,2)\n","\n","a_n = np.zeros((2,2))\n","b_n = np.ones((2,2))\n","c_n = np.identity(2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrKvfC3pJeQy","colab_type":"code","colab":{}},"source":["d_t = torch.from_numpy(c_n)\n","d_n = c_t.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Af5FIMZkJoCY","colab_type":"code","outputId":"a80da051-05a9-4e2c-ae81-91e207a01064","executionInfo":{"status":"ok","timestamp":1570551282222,"user_tz":-180,"elapsed":814,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["torch.matmul(a_t,b_t)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0.],\n","        [0., 0.]])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"uVgv7QY0Jt1b","colab_type":"code","outputId":"2653e41b-e75f-462c-edf9-40f7ea62af77","executionInfo":{"status":"ok","timestamp":1570551298264,"user_tz":-180,"elapsed":665,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a_t.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"GcHvr59NHP2m","colab_type":"text"},"source":["Давайте начнем практиковать построение тензоров в библиотеке PyTorch. Как вы знаете, тензоры - это массивы с произвольным числом измерений, соответствующих ndarrays NumPy. Вы собираетесь создать случайный тензор размером 3 на 3 и установить его в переменную your_first_tensor. Затем вам нужно будет напечатать его. Наконец, вычислите его размер в переменной tenor_size и выведите его значение."]},{"cell_type":"code","metadata":{"id":"1FJgwKXfHJkF","colab_type":"code","colab":{}},"source":["# Import torch\n","import torch\n","\n","# Create random tensor of size 3 by 3\n","your_first_tensor = \n","\n","# Calculate the shape of the tensor\n","tensor_size = \n","\n","# Print the values of the tensor and its shape\n","print()\n","print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u55-fsZUKGfV","colab_type":"text"},"source":["Давайте поэкспериментируем с этими двумя типами матриц. Вы собираетесь построить матрицу из них с формой 3 на 3, называемую tenns_of_ones, и единичную матрицу той же формы, называемую identity_tensor. Мы посмотрим, что произойдет, когда мы умножим эти две матрицы, и что произойдет, если мы сделаем их поэлементное умножение."]},{"cell_type":"code","metadata":{"id":"TRE_psDPKG_p","colab_type":"code","colab":{}},"source":["# Create a matrix of ones with shape 3 by 3\n","tensor_of_ones = \n","\n","# Create an identity matrix with shape 3 by 3\n","identity_tensor = \n","\n","# Do a matrix mulitplication of tensor_of_ones with identity_tensor\n","matrices_multiplied = \n","print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nk3VKjD1Kxsm","colab_type":"text"},"source":["Pytorch оперирует вычислительными графами. \n","Прямой и обратный шаг - важные составляющие вычислений и в нейронной сети. Вспоминаем прямой проход по графу\n","\n","2. Прямой проход (Forward pass)\n","\n","Давайте сделаем что-то похожее на нейронную сеть. Расчетный граф приведен ниже. Вы собираетесь инициализировать 3 больших случайных тензора, а затем выполнить операции, как указано в вычислительном графе. Последняя операция - это среднее значение тензора, данное torch.mean (your_tensor)."]},{"cell_type":"markdown","metadata":{"id":"y1MEMszPOLQN","colab_type":"text"},"source":["![](https://drive.google.com/uc?export=view&id=1d_EZNaGCHpVx89MFZga11zycok-4dRZM)"]},{"cell_type":"code","metadata":{"id":"N_LmrXhWKa7t","colab_type":"code","colab":{}},"source":["# Initialize tensors x, y and z\n","x = torch.rand(____, ____)\n","y = ____\n","z = ____\n","\n","# Multiply x with y\n","q = ____\n","\n","# Multiply elementwise z with q\n","f = ____\n","\n","mean_f = torch.mean(f)\n","print(mean_f)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqT16DfyL91r","colab_type":"text"},"source":["3. Backpropagation шаг осуществляется посредством автодифференцирования в Pytorch. Вспоминаем обратный проход по графу и вычисление градиента"]},{"cell_type":"markdown","metadata":{"id":"J2Iql0_2M_sZ","colab_type":"text"},"source":["![](https://drive.google.com/uc?export=view&id=1-heFApDjrJJG9PHvsBQ5kKERx5_zKVuZ)"]},{"cell_type":"markdown","metadata":{"id":"xRiaLZJKQHw6","colab_type":"text"},"source":["![](https://drive.google.com/uc?export=view&id=1evwhUrBrBepGPXbL2RraBXkSgWz_K-eo)"]},{"cell_type":"code","metadata":{"id":"qSpWwITfKoGP","colab_type":"code","colab":{}},"source":["# Initialize x, y and z to values 4, -3 and 5\n","x = torch.tensor(4., ____)\n","y = torch.tensor(____., ____)\n","z = ____\n","\n","# Set q to sum of x and y, set f to product of q with z\n","q = ____\n","f = ____\n","\n","# Compute the derivatives\n","f.____\n","\n","# Print the gradients\n","print(\"Gradient of x is: \" + str(____))\n","print(\"Gradient of y is: \" + str(____))\n","print(\"Gradient of z is: \" + str(____))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dYsEuqqRQFTi","colab_type":"text"},"source":["Помните упражнение в прямом проходе? Теперь, когда вы знаете, как вычислять производные, давайте сделаем шаг вперед и начнем вычислять градиенты (производные от тензоров) вычислительного графа, построенного вами тогда. "]},{"cell_type":"code","metadata":{"id":"o_MpCB67RipF","colab_type":"code","colab":{}},"source":["# Multiply tensors x and y\n","q = ____\n","\n","# Elementwise multiply tensors z with q\n","f = ____\n","\n","mean_f = torch.mean(f)\n","\n","# Calculate the gradients\n","____"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq6AX1gkSCI5","colab_type":"text"},"source":["4. Полносвязные нейронные сети"]},{"cell_type":"code","metadata":{"id":"ldHD9E-_Wr4Y","colab_type":"code","colab":{}},"source":["import torch\n","\n","input_layer = torch.rand(10)\n","\n","w1 = torch.rand(10,20)\n","w2 = torch.rand(20,20)\n","w3 = torch.rand(20,4)\n","\n","h1 = torch.matmul(input_layer,w1)\n","h2 = torch.matmul(h1,w2)\n","\n","output_layer = torch.matmul(h2,w3)\n","\n","print(output_layer)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93lHCOSPXQRo","colab_type":"text"},"source":["Вы собираетесь построить нейронную сеть в PyTorch, используя сложный путь. В качестве входных данных будут использоваться изображения размером (28, 28), то есть изображения, содержащие 784 пикселя. Ваша сеть будет содержать слой input_layer (предоставляется для вас), скрытый слой с 200 единицами и выходной слой с 10 классами. Входной слой уже создан для вас. Вы собираетесь создать весовые коэффициенты, а затем выполнить умножение матриц, получая результаты из сети."]},{"cell_type":"code","metadata":{"id":"FpuNINZpSllM","colab_type":"code","colab":{}},"source":["# Initialize the weights of the neural network\n","weight_1 = torch.rand(____, ____)\n","weight_2 = ____\n","\n","# Multiply input_layer with weight_1\n","hidden_1 = torch.matmul(____, ____)\n","\n","# Multiply hidden_1 with weight_2\n","output_layer = ____\n","print(output_layer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmBSfoMSXMi9","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.fc1 = Linear(10,20)\n","    self.fc2 = Linear(20,20)\n","    self.output = nn.Linear(20,4)\n","    \n","  def forward(self,x):\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    x = self.output(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CeLcOpmBYRpz","colab_type":"text"},"source":["5. Ваша первая нейронная сеть PyTorch\n","\n","Вы собираетесь построить ту же нейронную сеть, которую вы создали в предыдущем упражнении, но теперь с помощью метода PyTorch. Напоминаем, что у вас есть 784 единицы на входном слое, 200 скрытых единиц и 10 единиц на выходном слое."]},{"cell_type":"code","metadata":{"id":"-0J-TFURYSSe","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        # Instantiate all 2 linear layers  \n","        self.fc1 = nn.Linear(____, ____)\n","        self.fc2 = ____\n","\n","    def forward(self, x):\n","      \n","        # Use the instantiated layers and return x\n","        x = self.fc1(x)\n","        x = ____\n","        return ____"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qbfNhIcfZT9h","colab_type":"text"},"source":["6. Функции активации (нелинейность)\n","\n","Многослойные нейронные сети без функции активации эквивалентны сети с одним слоем (линейной регрессии)"]},{"cell_type":"code","metadata":{"id":"KBNS5RJeZXdh","colab_type":"code","colab":{}},"source":["# Initialize input layer, weight_1, weight_2, weight_3\n","\n","# Calculate the first and second hidden layer\n","hidden_1 = torch.matmul(input_layer, weight_1)\n","hidden_2 = torch.matmul(hidden_1, weight_2)\n","\n","# Calculate the output\n","print(torch.matmul(hidden_2, weight_3))\n","\n","# Calculate weight_composed_1 and weight\n","weight_composed_1 = torch.matmul(weight_1, weight_2)\n","weight = torch.matmul(weight_composed_1, weight_3)\n","\n","# Multiply input_layer with weight\n","print(torch.matmul(input_layer, weight))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdbD86qKacGx","colab_type":"code","colab":{}},"source":["# Apply non-linearity on hidden_1 and hidden_2\n","hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n","hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n","print(torch.matmul(hidden_2_activated, weight_3))\n","\n","# Apply non-linearity in the product of first two weights. \n","weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n","\n","# Multiply `weight_composed_1_activated` with `weight_3\n","weight = torch.matmul(weight_composed_1_activated, weight_3)\n","\n","# Multiply input_layer with weight\n","print(torch.matmul(input_layer, weight))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kt_1OZqCbfnN","colab_type":"text"},"source":["Нейронные сети не должны иметь одинаковое количество единиц в каждом слое. Здесь вы снова поэкспериментируете с функцией активации ReLU, но на этот раз у нас будет разное количество единиц в слоях нейронной сети. Входной слой по-прежнему будет иметь 4 объекта, но тогда первый скрытый слой будет иметь 6 единиц, а выходной слой будет иметь 2 единицы."]},{"cell_type":"markdown","metadata":{"id":"fWKZ-gr5b4bI","colab_type":"text"},"source":["![](https://drive.google.com/uc?export=view&id=1cAZ4wYpgUOUFOo4IiHD9MaNuFSOY4YOo)"]},{"cell_type":"code","metadata":{"id":"nc1D0z1XayH_","colab_type":"code","colab":{}},"source":["# Instantiate ReLU activation function as relu\n","import torch.nn as nn\n","relu = nn.ReLU()\n","\n","# Initialize weight_1 and weight_2 with random numbers\n","weight_1 = torch.rand(4, 6)\n","weight_2 = torch.rand(6, 2)\n","\n","# Multiply input_layer with weight_1\n","hidden_1 = torch.matmul(input_layer, weight_1)\n","\n","# Apply ReLU activation function over hidden_1 and multiply with weight_2\n","hidden_1_activated = relu(hidden_1)\n","print(torch.matmul(hidden_1_activated, weight_2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uLpXOLne5aS","colab_type":"text"},"source":["7. Функция потерь (кросс-энтропия)\n","\n","Функция потерь должна быть дифференцируема, какая нибудь доля неправильных ответов - не подойдет. Кросс-энтропия хорошо работает для большинства задач. \n","\n","![](https://drive.google.com/uc?export=view&id=1x2kwtTqIVJyDP6Wd8BqTK6cd0pgJF1lH)"]},{"cell_type":"markdown","metadata":{"id":"ovndIRUxgSER","colab_type":"text"},"source":["Функция расчета потерь в PyTorch\n","Вы собираетесь написать код предыдущего упражнения и убедиться, что мы правильно рассчитали потери. Прогнозируемые баллы -1,2 для класса 0 (кошка), 0,12 для класса 1 (автомобиль) и 4,8 для класса 2 (лягушка). Основная правда - класс 2 (лягушка). Вычислить функцию потерь в PyTorch."]},{"cell_type":"code","metadata":{"id":"bxNfHrDsfC6c","colab_type":"code","colab":{}},"source":["# Initialize the scores and ground truth\n","logits = torch.tensor([[-1.2,0.12,4.8]])\n","ground_truth = torch.tensor([2])\n","\n","# Instantiate cross entropy loss\n","criterion = nn.CrossEntropyLoss()\n","\n","# Compute and print the loss\n","loss = criterion(logits,ground_truth)\n","print(loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHTG_0Dqh6X_","colab_type":"text"},"source":["Функция потери случайных результатов\n","Если нейронная сеть предсказывает случайные оценки, какова будет ее функция потерь? Давайте выясним это в PyTorch. В нейронной сети будет 1000 классов rand(1,1000), каждый из которых имеет случайный счет. Для наземной правды у него будет класс 111. Рассчитайте функцию потерь."]},{"cell_type":"code","metadata":{"id":"h3nE4YTFgEaZ","colab_type":"code","colab":{}},"source":["# Import torch and torch.nn\n","____\n","____\n","\n","# Initialize logits and ground truth\n","logits = ____\n","ground_truth = ____\n","\n","# Instantiate cross-entropy loss\n","____\n","\n","# Calculate and print the loss\n","loss = ____\n","____"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mh2TCGZ_qE6i","colab_type":"text"},"source":["###  8. Работа с датасетами в Pytorch\n","MNIST и CIFAR-10 датасет"]},{"cell_type":"code","metadata":{"id":"pEcHO0CWqIpS","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torch.utils.data \n","import torchvision.transforms as transforms"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLH7uVaEqdU2","colab_type":"code","colab":{}},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(), \n","    transforms.Normalize((0.4941, 0.48216, 0.44653), (0.24703, 0.24349, 0.26159))]) # mean and std for each channel"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0DtqaE2trOos","colab_type":"text"},"source":["#### Datasets и Dataloaders"]},{"cell_type":"code","metadata":{"id":"eLcRdv3prAUv","colab_type":"code","outputId":"e58ae73d-a237-4bc5-958b-4932c5c46f1f","executionInfo":{"status":"ok","timestamp":1570560155188,"user_tz":-180,"elapsed":7644,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["trainset  = torchvision.datasets.CIFAR10(root='./data', train=True, \n","                                         download=True, transform=transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n","                                         download=True, transform=transform)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["170500096it [00:03, 43252610.60it/s]                               \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QlsRvcHQrf-C","colab_type":"code","outputId":"71cee65a-4a48-4896-accb-70ed45fe46b8","executionInfo":{"status":"ok","timestamp":1570560165748,"user_tz":-180,"elapsed":1868,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["%ll"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 8\n","drwxr-xr-x 3 root 4096 Oct  8 18:42 \u001b[0m\u001b[01;34mdata\u001b[0m/\n","drwxr-xr-x 1 root 4096 Aug 27 16:17 \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rr5SHWQtrj-d","colab_type":"code","colab":{}},"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n","                                          shuffle=True, num_workers=4)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n","                                          shuffle=False, num_workers=4) # processes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ykb4fGJesq2_","colab_type":"code","outputId":"c3d82613-c5a7-4758-c852-c43e28dac438","executionInfo":{"status":"ok","timestamp":1570560618300,"user_tz":-180,"elapsed":621,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(trainloader.dataset.data.shape, testloader.dataset.data.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(50000, 32, 32, 3) (10000, 32, 32, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cDKRJTFCtU58","colab_type":"code","outputId":"fb64841d-8a85-4b75-848e-e7900f2d901c","executionInfo":{"status":"ok","timestamp":1570560634714,"user_tz":-180,"elapsed":626,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["testloader.batch_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"-JPocmCbs1Mp","colab_type":"code","outputId":"3da12f9a-ffad-4641-b9fd-582e42473402","executionInfo":{"status":"ok","timestamp":1570560645736,"user_tz":-180,"elapsed":654,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["testloader.sampler"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.sampler.SequentialSampler at 0x7fd5bee51dd8>"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"jELnBHW3tha6","colab_type":"text"},"source":["Подготовка набора данных MNIST\n","Вы собираетесь подготовить загрузчики данных для обучения и тестирования MNIST. Как мы объяснили в лекции, MNIST имеет некоторые отличия от CIFAR-10, при этом основное отличие состоит в том, что изображения MNIST имеют оттенки серого (на основе 1 канала) вместо RGB (3 канала). mean = 0.1307, std = 0.3081"]},{"cell_type":"code","metadata":{"id":"F3DATd3ttDRx","colab_type":"code","colab":{}},"source":["# Transform the data to torch tensors and normalize it \n","transform = transforms.Compose([transforms.____,\n","\t\t\t\t\t\t\t\ttransforms.____((____), ((____)))])\n","\n","# Prepare training set and testing set\n","trainset = torchvision.datasets.MNIST('mnist', train=____, \n","\t\t\t\t\t\t\t\t\t  download=____, transform=____)\n","testset = ____('mnist', ____,\n","\t\t\t   ____, ____)\n","\n","# Prepare training loader and testing loader\n","trainloader = torch.utils.data.DataLoader(____, ____,\n","                                          ____, num_workers=0)\n","testloader = torch.utils.data.DataLoader(____, ____,\n","\t\t\t\t\t\t\t\t\t\t ____, num_workers=0) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkpcEhG8xr0I","colab_type":"text"},"source":["### 9. Обучение нейронных сетей"]},{"cell_type":"code","metadata":{"id":"CgeT1TIza_E1","colab_type":"code","outputId":"1174804c-8fc6-42b6-c369-e58a45c371ea","executionInfo":{"status":"ok","timestamp":1570572606966,"user_tz":-180,"elapsed":2944,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["trainset  = torchvision.datasets.CIFAR10(root='./data', train=True, \n","                                         download=True, transform=transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n","                                         download=True, transform=transform)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5DC9yi6Fa_ij","colab_type":"code","colab":{}},"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n","                                          shuffle=True, num_workers=4)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n","                                          shuffle=False, num_workers=4) # processes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVpecA6uanIb","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","\n","\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.fc1 = nn.Linear(32*32*3,500) # 500 нейронов в первом слое\n","    self.fc2 = nn.Linear(500,10) # 10 классов\n","    \n","  def forward(self,x):\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_HY-WB2ZG1o","colab_type":"code","outputId":"5ab53a63-569f-4db8-b6b2-dd7d4717b5de","executionInfo":{"status":"error","timestamp":1570573124506,"user_tz":-180,"elapsed":292,"user":{"displayName":"Sergey Abdurakipov","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB8I6seP7fcXiweH_fKVVW9D3b5V-NSqWXAjV7-iA=s64","userId":"16759802806143231754"}},"colab":{"base_uri":"https://localhost:8080/","height":335}},"source":["net  = Net()\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.Adam(net.parameters(), lr=3e-04)\n","\n","for epoch in range(10):\n","  for i, data in enumerate(trainloader, 0):\n","    #Get the inputs\n","    inputs, labels = data\n","    inputs = inputs.view(-1, 32*32*3)\n","    \n","    #Zero the parameter gradient \n","    optimizer.zero_grad()\n","    \n","    # Forward + backward + optimize\n","    \n","    outputs = net(inputs)\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-dcd66b334af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"4vrObHmvbCs-","colab_type":"code","colab":{}},"source":["correct, total = 0, 0\n","predictions = []\n","net.eval()\n","for i, data in enumerate(testloader, 0):\n","  inputs, data = data\n","  outputs = net(inputs)\n","  _, predicted = torch.max(outputs.data, 1)\n","  predictions.append(outputs)\n","  total += labels.size(0)\n","  correct += (predicted == labels).sum().item()\n","  \n","print('The testing set accuracy of the network is: %d %%' % (100*correct/total))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vN8XN6oOcltR","colab_type":"text"},"source":["Создайте класс для нейронной сети, которая будет использоваться для обучения на наборе данных MNIST. Набор данных содержит изображения (28, 28, 1), поэтому вы должны вычесть размер входного слоя. Для скрытого слоя используйте 200 нейронов, а для выходного слоя - 10 нейронов (по 1 для каждого класса). Для функции активации используйте relu функциональным способом (nn.Functional как F)"]},{"cell_type":"code","metadata":{"id":"d2Vdz4kpcmO4","colab_type":"code","colab":{}},"source":["# Define the class Net\n","____:\n","    def __init__(self):    \n","    \t# Define all the parameters of the net\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(____ * ____ * ____, ____)\n","        self.fc2 = ____\n","\n","    def forward(self, x):   \n","    \t# Do the forward pass\n","        x = F.relu(self.fc1(____))\n","        x = self.____(____)\n","        return ____"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-bjhemNdAy3","colab_type":"code","colab":{}},"source":["# Instantiate the Adam optimizer and Cross-Entropy loss function\n","optimizer = optim.Adam(____.parameters(), lr=3e-4)\n","criterion = nn.____\n","  \n","for batch_idx, data_target in enumerate(train_loader):\n","    data = data_target[0]\n","    target = data_target[1]\n","    data = data.view(-1, 28 * 28)\n","    optimizer.zero_grad()\n","\n","    # Complete a forward pass\n","    output = model(____)\n","\n","    # Compute the loss, gradients and change the weights\n","    loss = ____\n","    loss.____\n","    optimizer.____"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wt5s2nRJeGI5","colab_type":"text"},"source":["Теперь, когда вы обучили сеть, используйте ее для прогнозирования данных в тестовом наборе данных. Сеть называется - модель (как в предыдущем упражнении), а загрузчик называется test_loader. Мы уже инициализировали переменные total и correct до 0."]},{"cell_type":"code","metadata":{"id":"mfswMkNddqLO","colab_type":"code","colab":{}},"source":["# Set the model in eval mode\n","model.____\n","\n","for i, data in enumerate(test_loader, 0):\n","    inputs, labels = data\n","    \n","    # Put each image into a vector\n","    inputs = inputs.view(-1, ____)\n","    \n","    # Do the forward pass and get the predictions\n","    outputs = ____\n","    _, outputs = ____\n","    total += labels.size(0)\n","    correct += (outputs == labels).sum().item()\n","print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIoRqz6gdwGq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}